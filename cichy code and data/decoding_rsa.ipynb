{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "# Representational Similarity Analysis\n",
    "\n",
    "\n",
    "Representational Similarity Analysis is used to perform summary statistics\n",
    "on supervised classifications where the number of classes is relatively high.\n",
    "It consists in characterizing the structure of the confusion matrix to infer\n",
    "the similarity between brain responses and serves as a proxy for characterizing\n",
    "the space of mental representations [1]_ [2]_ [3]_.\n",
    "\n",
    "In this example, we perform RSA on responses to 24 object images (among\n",
    "a list of 92 images). Subjects were presented with images of human, animal\n",
    "and inanimate objects [4]_. Here we use the 24 unique images of faces\n",
    "and body parts.\n",
    "\n",
    "References\n",
    "----------\n",
    "\n",
    ".. [1] Shepard, R. \"Multidimensional scaling, tree-fitting, and clustering.\"\n",
    "       Science 210.4468 (1980): 390-398.\n",
    ".. [2] Laakso, A. & Cottrell, G.. \"Content and cluster analysis:\n",
    "       assessing representational similarity in neural systems.\" Philosophical\n",
    "       psychology 13.1 (2000): 47-76.\n",
    ".. [3] Kriegeskorte, N., Marieke, M., & Bandettini.  P. \"Representational\n",
    "       similarity analysis-connecting the branches of systems neuroscience.\"\n",
    "       Frontiers in systems neuroscience 2 (2008): 4.\n",
    ".. [4] Cichy, R. M., Pantazis, D., & Oliva, A. \"Resolving human object\n",
    "       recognition in space and time.\" Nature neuroscience (2014): 17(3),\n",
    "       455-462.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Authors: Jean-Remi King <jeanremi.king@gmail.com>\n",
    "#          Jaakko Leppakangas <jaeilepp@student.jyu.fi>\n",
    "#          Alexandre Gramfort <alexandre.gramfort@telecom-paristech.fr>\n",
    "#\n",
    "# License: BSD (3-clause)\n",
    "\n",
    "import os.path as op\n",
    "import numpy as np\n",
    "from pandas import read_csv\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.manifold import MDS\n",
    "\n",
    "import mne\n",
    "from mne.io import read_raw_fif, concatenate_raws\n",
    "from mne.datasets import visual_92_categories\n",
    "\n",
    "print(__doc__)\n",
    "\n",
    "data_path = visual_92_categories.data_path()\n",
    "\n",
    "# Define stimulus - trigger mapping\n",
    "fname = op.join(data_path, 'visual_stimuli.csv')\n",
    "conds = read_csv(fname)\n",
    "print(conds.head(5))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's restrict the number of conditions to speed up computation\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_trigger = 24\n",
    "conds = conds[:max_trigger]  # take only the first 24 rows"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define stimulus - trigger mapping\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "conditions = []\n",
    "for c in conds.values:\n",
    "    cond_tags = list(c[:2])\n",
    "    cond_tags += [('not-' if i == 0 else '') + conds.columns[k]\n",
    "                  for k, i in enumerate(c[2:], 2)]\n",
    "    conditions.append('/'.join(map(str, cond_tags)))\n",
    "print(conditions[:10])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's make the event_id dictionary\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "event_id = dict(zip(conditions, conds.trigger + 1))\n",
    "event_id['0/human bodypart/human/not-face/animal/natural']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Read MEG data\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_runs = 4  # 4 for full data (use less to speed up computations)\n",
    "fname = op.join(data_path, 'sample_subject_%i_tsss_mc.fif')\n",
    "raws = [read_raw_fif(fname % block) for block in range(n_runs)]\n",
    "raw = concatenate_raws(raws)\n",
    "\n",
    "events = mne.find_events(raw, min_duration=.002)\n",
    "\n",
    "events = events[events[:, 2] <= max_trigger]\n",
    "mne.viz.plot_events(events, sfreq=raw.info['sfreq'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Epoch data\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "picks = mne.pick_types(raw.info, meg=True)\n",
    "epochs = mne.Epochs(raw, events=events, event_id=event_id, baseline=None,\n",
    "                    picks=picks, tmin=-.1, tmax=.500, preload=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's plot some conditions\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs['face'].average().plot()\n",
    "epochs['not-face'].average().plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Representational Similarity Analysis (RSA) is a neuroimaging-specific\n",
    "appelation to refer to statistics applied to the confusion matrix\n",
    "also referred to as the representational dissimilarity matrices (RDM).\n",
    "\n",
    "Compared to the approach from Cichy et al. we'll use a multiclass\n",
    "classifier (Multinomial Logistic Regression) while the paper uses\n",
    "all pairwise binary classification task to make the RDM.\n",
    "Also we use here the ROC-AUC as performance metric while the\n",
    "paper uses accuracy. Finally here for the sake of time we use\n",
    "RSA on a window of data while Cichy et al. did it for all time\n",
    "instants separately.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Classify using the average signal in the window 50ms to 300ms\n",
    "# to focus the classifier on the time interval with best SNR.\n",
    "clf = make_pipeline(StandardScaler(),\n",
    "                    LogisticRegression(C=1, solver='lbfgs'))\n",
    "X = epochs.copy().crop(0.05, 0.3).get_data().mean(axis=2)\n",
    "y = epochs.events[:, 2]\n",
    "\n",
    "classes = set(y)\n",
    "cv = StratifiedKFold(n_splits=5, random_state=0, shuffle=True)\n",
    "\n",
    "# Compute confusion matrix for each cross-validation fold\n",
    "y_pred = np.zeros((len(y), len(classes)))\n",
    "for train, test in cv.split(X, y):\n",
    "    # Fit\n",
    "    clf.fit(X[train], y[train])\n",
    "    # Probabilistic prediction (necessary for ROC-AUC scoring metric)\n",
    "    y_pred[test] = clf.predict_proba(X[test])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compute confusion matrix using ROC-AUC\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "confusion = np.zeros((len(classes), len(classes)))\n",
    "for ii, train_class in enumerate(classes):\n",
    "    for jj in range(ii, len(classes)):\n",
    "        confusion[ii, jj] = roc_auc_score(y == train_class, y_pred[:, jj])\n",
    "        confusion[jj, ii] = confusion[ii, jj]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plot\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = [''] * 5 + ['face'] + [''] * 11 + ['bodypart'] + [''] * 6\n",
    "fig, ax = plt.subplots(1)\n",
    "im = ax.matshow(confusion, cmap='RdBu_r', clim=[0.3, 0.7])\n",
    "ax.set_yticks(range(len(classes)))\n",
    "ax.set_yticklabels(labels)\n",
    "ax.set_xticks(range(len(classes)))\n",
    "ax.set_xticklabels(labels, rotation=40, ha='left')\n",
    "ax.axhline(11.5, color='k')\n",
    "ax.axvline(11.5, color='k')\n",
    "plt.colorbar(im)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Confusion matrix related to mental representations have been historically\n",
    "summarized with dimensionality reduction using multi-dimensional scaling [1].\n",
    "See how the face samples cluster together.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1)\n",
    "mds = MDS(2, random_state=0, dissimilarity='precomputed')\n",
    "chance = 0.5\n",
    "summary = mds.fit_transform(chance - confusion)\n",
    "cmap = plt.get_cmap('rainbow')\n",
    "colors = ['r', 'b']\n",
    "names = list(conds['condition'].values)\n",
    "for color, name in zip(colors, set(names)):\n",
    "    sel = np.where([this_name == name for this_name in names])[0]\n",
    "    size = 500 if name == 'human face' else 100\n",
    "    ax.scatter(summary[sel, 0], summary[sel, 1], s=size,\n",
    "               facecolors=color, label=name, edgecolors='k')\n",
    "ax.axis('off')\n",
    "ax.legend(loc='lower right', scatterpoints=1, ncol=2)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
